{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP9418 - Assignment 1 - Bayesian Network, Na√Øve Bayes and TAN Bayes Classifiers\n",
    "\n",
    "## UNSW Sydney"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Student name 1 - zID1\n",
    "- Student name 2 - zID2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "**Submission deadline:** Sunday, 30th June 2024, at 18:00:00 AEDT.\n",
    "\n",
    "**Late Submission Policy:** The penalty is set at $5\\%$ per late day for a maximum of 5 days. This is the UNSW standard late penalty. For example, if an assignment receives an on-time mark of $70/100$ and is submitted three days late, it will receive a mark reduction of $70/100*15\\%$. After five days, the assignment will receive a mark reduction of $100\\%$.\n",
    "\n",
    "**Form of Submission:** This is an **individual** or group of **two students** assignment. Write the name(s) and zID(s) in this Jupyter notebook. **If submitted in a group, only one member should submit the assignment. Also, create a group on WebCMS by clicking on Groups and Create and include both group members**.\n",
    "\n",
    "You can reuse any piece of source code developed in the tutorials.\n",
    "\n",
    "You can submit your solution via [WebCMS](https://webcms3.cse.unsw.edu.au/COMP9418/24T2).\n",
    "\n",
    "Alternatively, you can submit your solution using give. On a CSE Linux machine, type the following on the command line:\n",
    "\n",
    "``$ give cs9418 ass1 solution.zip``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical prerequisites\n",
    "\n",
    "These are the libraries you are allowed to use. No other libraries will be accepted. Make sure you are using Python 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allowed libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import heapq as pq\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import math\n",
    "from itertools import product, combinations\n",
    "from graphviz import Digraph\n",
    "from tabulate import tabulate\n",
    "import copy\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the Python files we developed in tutorials or any other code from the tutorials. The cell below downloads the tutorial libraries from the Github repo. If you want to use your libraries, do **not** run the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os.path\n",
    "# import wget\n",
    "\n",
    "# if not os.path.exists(\"DiscreteFactors.py\"):\n",
    "#     !python -m wget 'https://raw.githubusercontent.com/UNSW-COMP9418/libraries/main/DiscreteFactors.py'\n",
    "# if not os.path.exists(\"Graph.py\"):\n",
    "#     !python -m wget 'https://raw.githubusercontent.com/UNSW-COMP9418/libraries/main/Graph.py'\n",
    "# if not os.path.exists(\"BayesNet_VE.psy\"):\n",
    "#     !python -m wget 'https://raw.githubusercontent.com/UNSW-COMP9418/libraries/main/BayesNet_VE.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DiscreteFactors import Factor\n",
    "from Graph import Graph\n",
    "from BayesNet_VE import BayesNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 0 - Initialise graph\n",
    "\n",
    "Create a graph ``G`` that represents the following network by filling in the edge lists.\n",
    "![Bayes Net](BayesNet.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Graph({\n",
    "    \"LymphNodes\": [],\n",
    "    'Metastasis': [\"LymphNodes\"],\n",
    "    \"BC\": [\"Metastasis\",\"Mass\",\"AD\",\"NippleDischarge\",\"SkinRetract\",\"MC\"],\n",
    "    \"Age\": [\"BC\"],\n",
    "    \"Location\": [\"BC\"],\n",
    "    \"MC\": [],\n",
    "    \"SkinRetract\": [],\n",
    "    \"NippleDischarge\": [],\n",
    "    \"AD\": [\"FibrTissueDev\"],\n",
    "    \"FibrTissueDev\": [\"NippleDischarge\",\"SkinRetract\",\"Spiculation\"],\n",
    "    \"Spiculation\": [\"Margin\"],\n",
    "    \"Margin\": [],\n",
    "    \"Mass\": [\"Margin\",\"Shape\",\"Size\"],\n",
    "    \"Shape\": [],\n",
    "    \"Size\": [],\n",
    "    \"BreastDensity\": [\"Mass\"],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "with open('bc.csv') as file:\n",
    "    data = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [10 Marks] Task 1 - Efficient d-separation test\n",
    "\n",
    "Implement the efficient version of the d-separation algorithm in a function ``BN.d_separation(X, Z, Y)`` that returns a boolean: ``True`` if ``X`` is d-separated from ``Y`` given ``Z`` in the Bayes Net ``BN`` and ``False`` otherwise.\n",
    "\n",
    "* ``X``,``Y`` and ``Z`` are Python sets, each containing a set of variable names. \n",
    "* Variable names may be strings or integers and can be assumed to be nodes of the Bayes Net. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop your code for BN.d_separation(X, Z, Y) in this cell\n",
    "\n",
    "class BayesNet(BayesNet):\n",
    "\n",
    "    def d_separation(self, X, Z, Y):\n",
    "        '''\n",
    "        Arguments:\n",
    "            X, Z and Y:  Python set objects with node identifiers.\n",
    "        Returns:\n",
    "            True if X is d-separated from Y given Z or False otherwise.\n",
    "        '''\n",
    "        G = self.graph.copy()\n",
    "        \n",
    "        #1. leaves and not in X Z Y\n",
    "        for node in self.graph:\n",
    "            if not len(G.children(node)) and node not in (X | Y | Z): \n",
    "                G.remove_node(node)\n",
    "\n",
    "        #2. delete all edges outgoing from nodes in Z.\n",
    "        for node in Z:\n",
    "            G.remove_outgoing_from(node)\n",
    "\n",
    "        undriG =  G.convert_to_undirected()\n",
    "\n",
    "        #3. test if X and Y are connected\n",
    "        for x in X:\n",
    "            visit = undriG.dfs(x)\n",
    "            for y in Y:\n",
    "                if visit[y] == \"black\":\n",
    "                    return False\n",
    "                    \n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed test case\n",
      "Passed test case\n"
     ]
    }
   ],
   "source": [
    "##################################################################################\n",
    "## TEST CODE                                                                    ##\n",
    "## Note: More hidden tests will be used. You should create more tests yourself. ##\n",
    "##################################################################################\n",
    "\n",
    "def _test(statement):\n",
    "    if statement:\n",
    "        print(\"Passed test case\")\n",
    "    else:\n",
    "        print(\"Failed test case !!!\")\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "BN = BayesNet(G)\n",
    "\n",
    "_test(BN.d_separation(set(['Age']), set(['BC']), set(['AD'])))\n",
    "_test(not BN.d_separation(set(['Spiculation', 'SkinRetract']), set(['MC', 'Size']), set(['Age'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5 Marks] Task 2 - Markov blanket\n",
    "\n",
    "The Markov blanket for a variable ``X`` is a set of variables that, when observed, will render every other variable irrelevant to ``X``. If the distribution is induced by DAG ``G``, then a Markov blanket for variable $X$ can be constructed using ``X``'s parents, children, and spouses in ``G``. A variable ``Y`` is a spouse of ``X`` if the two variables have a common child in ``G``.\n",
    "\n",
    "In this exercise, we will implement a function ``BN.Markov_blanket(X)`` that returns a Python set with the Markov blanket of a node ``X`` in the BayesNet ``BN`` as described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop your code for BN.Markov_blanket(X) in this cell\n",
    "\n",
    "class BayesNet(BayesNet):\n",
    "\n",
    "    def Markov_blanket(self, X):\n",
    "        '''\n",
    "        Arguments:\n",
    "            X:   is a node (variable) in the Bayes Net.\n",
    "        Returns: \n",
    "            A python set with the Markov blanked of X in the Bayes Net.\n",
    "        '''\n",
    "        G = self.graph.copy()\n",
    "        Mb = set(G.children(X))\n",
    "        \n",
    "        #1. add spouses\n",
    "        for node in self.graph:\n",
    "            if node not in Mb and node != X:\n",
    "                for child in G.children(X):\n",
    "                    if child in G.children(node):\n",
    "                        Mb.add(node)\n",
    "                        break\n",
    "\n",
    "        #2. add parents\n",
    "        for node in self.graph:\n",
    "            if X in G.children(node):\n",
    "                Mb.add(node)\n",
    "\n",
    "        return Mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed test case\n",
      "Passed test case\n"
     ]
    }
   ],
   "source": [
    "##################################################################################\n",
    "## TEST CODE                                                                    ##\n",
    "## Note: More hidden tests will be used. You should create more tests yourself. ##\n",
    "##################################################################################\n",
    "\n",
    "def _test(statement):\n",
    "    if statement:\n",
    "        print(\"Passed test case\")\n",
    "    else:\n",
    "        print(\"Failed test case !!!\")\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "BN = BayesNet(G)\n",
    "\n",
    "_test(BN.Markov_blanket('Mass') == set(['Margin', 'Size', 'Shape', 'BreastDensity', 'BC', 'Spiculation']))\n",
    "_test(BN.Markov_blanket('Age') == set(['Location', 'BC']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting Tasks 1 and 2 together\n",
    "\n",
    "This task is optional and will not be marked, but you can use it to test your code further. According to the Markov blanket definition: A Markov blanket for a variable $X \\in \\textbf{X}$ is the set of variables $\\textbf{B} \\subseteq \\textbf{X}$ such that $X \\notin \\textbf{B}$ and $X \\perp \\textbf{X} \\setminus (\\textbf{B} \\cup \\{ X \\}) | \\textbf{B}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop your code to test your d-separation and Markov blanket implementations using the definition above.\n",
    "\n",
    "set_X = {...}                                        # Set of all nodes in the graph\n",
    "for X in set_X:\n",
    "    mb = ...                                         # Markov_blanket of X\n",
    "    ...                                              # Independence test according to the definition above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5 Marks] Task 3 - Learning the outcome space from data\n",
    "\n",
    "Now, we will implement a series of functions to learn Bayesian network parameters from data. We will start by learning the outcome space of the variables in a Bayesian network. Remind from the tutorials that the outcome space is a Python dictionary that maps the variable names to a tuple with the possible values this variable can have.\n",
    "\n",
    "Implement a function ``BN.learn_outcome_space(data)`` that learns the outcome space (the valid values for each variable) from the pandas dataframe ``data``. \n",
    "\n",
    "This function should store the learned outcome space inside the BayesNet object using the attribute ``self.outcomeSpace``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop your code for BN.learn_outcome_space(data) in this cell\n",
    "\n",
    "class BayesNet(BayesNet):\n",
    "\n",
    "    def learn_outcome_space(self, data):\n",
    "        '''\n",
    "        Arguments:\n",
    "            data:    A pandas dataframe\n",
    "        Returns: \n",
    "            Store the learned outcome space in self.outcomeSpace\n",
    "            \n",
    "        '''\n",
    "        self.outcomeSpace = {}\n",
    "        for node in data.columns:\n",
    "            self.outcomeSpace[node] = tuple(data[node].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed test case\n"
     ]
    }
   ],
   "source": [
    "##################################################################################\n",
    "## TEST CODE                                                                    ##\n",
    "## Note: More hidden tests will be used. You should create more tests yourself. ##\n",
    "##################################################################################\n",
    "\n",
    "def _test(statement):\n",
    "    if statement:\n",
    "        print(\"Passed test case\")\n",
    "    else:\n",
    "        print(\"Failed test case !!!\")\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "BN = BayesNet(G)\n",
    "\n",
    "BN.learn_outcome_space(data)\n",
    "\n",
    "outcomes = BN.outcomeSpace['BreastDensity']\n",
    "answer = ('high', 'medium', 'low')\n",
    "_test(len(outcomes) == len(answer) and set(outcomes) == set(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5 Marks] Task 4 - Estimate Bayesian network parameters from data\n",
    "\n",
    "Implement a method ``BN.learn_parameters(data, alpha=1)`` that learns the model parameters from `data` for the Bayes Net ``BN``. This function is similar to the ``learn_parameters`` from tutorials, but it should also implement laplacian smoothing with parameter $\\alpha$.\n",
    "\n",
    "This function should store the learned parameters inside the BayesNet object using the attribute ``self.factors``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for BN.learn_parameters(data, alpha) in this cell\n",
    "\n",
    "class BayesNet(BayesNet):\n",
    "    def learn_parameters(self, data, alpha=1):\n",
    "        '''\n",
    "        Arguments:\n",
    "            data:    A pandas dataframe\n",
    "            alpha:   Laplacian smoothing parameter\n",
    "        Returns:\n",
    "            Store the learned parameters in self.factors\n",
    "        '''\n",
    "        def allEqualThisIndex(dict_of_arrays, **fixed_vars):\n",
    "            # base index is a boolean vector, everywhere true\n",
    "            first_array = dict_of_arrays[list(dict_of_arrays.keys())[0]]\n",
    "            index = np.ones_like(first_array, dtype=np.bool_)\n",
    "            for var_name, var_val in fixed_vars.items():\n",
    "                index = index & (np.asarray(dict_of_arrays[var_name])==var_val)\n",
    "            return index\n",
    "    \n",
    "        graphT = self.graph.transpose()\n",
    "        for node, parents in graphT.adj_list.items():\n",
    "            var_outcomes = self.outcomeSpace[node] #value types of this node \n",
    "            parent_outcomes=[]; X=len(var_outcomes)\n",
    "            for var in (parents):\n",
    "                parent_outcomes.append(self.outcomeSpace[var])\n",
    "                X = X * len(var)\n",
    "\n",
    "            # cartesian product to generate a table of all possible outcomes\n",
    "            all_parent_combinations = product(*parent_outcomes)\n",
    "\n",
    "            f = Factor(list(parents)+[node], self.outcomeSpace)\n",
    "        \n",
    "            for i, parent_combination in enumerate(all_parent_combinations):\n",
    "                parent_vars = dict(zip(parents, parent_combination))\n",
    "                \n",
    "                parent_index = allEqualThisIndex(data, **parent_vars)\n",
    "                for var_outcome in var_outcomes:\n",
    "                    var_index = (np.asarray(data[node])==var_outcome)\n",
    "                    f[tuple(list(parent_combination)+[var_outcome])] = ((var_index & parent_index).sum() + alpha) / (len(data) + alpha*X)\n",
    "            \n",
    "            self.factors[node] = f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed test case\n"
     ]
    }
   ],
   "source": [
    "##################################################################################\n",
    "## TEST CODE                                                                    ##\n",
    "## Note: More hidden tests will be used. You should create more tests yourself. ##\n",
    "##################################################################################\n",
    "\n",
    "def _test(statement):\n",
    "    if statement:\n",
    "        print(\"Passed test case\")\n",
    "    else:\n",
    "        print(\"Failed test case !!!\")\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "BN = BayesNet(G)\n",
    "\n",
    "BN.learn_outcome_space(data)\n",
    "BN.learn_parameters(data, alpha=1)\n",
    "\n",
    "_test(BN.factors['Age']['35-49'] == 0.248000399920016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5 Marks] Task 5 - Bayesian network classification\n",
    "\n",
    "We will now implement two related methods, ``predict_proba`` and ``predict``. We start with ``predict_proba``, and the implementation of ``predict`` will be just a few lines of code with a call to ``predict_proba``.\n",
    "\n",
    "The method ``BN.model.predict_proba(class_var, evidence)`` **efficiently** computes the probability of an attribute ``class_var`` with complete data. As we are working with complete data, ``evidence`` instantiates all variables in the Bayesian network `BN` but `class_var`. This method returns a ``DiscreteFactor`` object with ``class_var`` as a single variable and the probabilities associated with each ``class_var`` value.\n",
    "\n",
    "The method ``BN.model.predict(class_var, evidence)`` is a direct consequence of the previous method. It returns the MPE value for the attribute `class_var`.\n",
    "\n",
    "This task requires an **efficient** implementation that differs from the one done in the tutorials, as it will only involve relevant factors. Ensure you watched Lecture 6 when we discuss the design and implementation of classifiers with complete data.\n",
    "\n",
    "**Pro tip**: Our library has an ``evidence2`` method that sets evidence for a variable ``X`` and removes ``X`` from the factor domain. This method makes things easier when we want a resulting factor that does not mention the evidence variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for BN.predict_proba(class_var, evidence) and BN.predict(class_var, evidence) in this cell\n",
    "\n",
    "class BayesNet(BayesNet):\n",
    "\n",
    "    def predict_proba(self, class_var, evidence):\n",
    "        f = Factor(tuple(), {}) # trivial factor\n",
    "        '''\n",
    "        Arguments:\n",
    "            class_var:   Variable identifier to be classified\n",
    "            evidence:    Python dictionary with one instantiation to all variables but class_var\n",
    "        Returns:\n",
    "            A factor object with class_var as the single variable and the probabilities associated with each ``class_var`` value given evidence\n",
    "        '''\n",
    "        return f\n",
    "    \n",
    "    def predict(self, class_var, evidence):\n",
    "        '''\n",
    "        Arguments:\n",
    "            class_var:   Variable identifier to be classified\n",
    "            evidence:    Python dictionary with one instantiation to all variables but class_var\n",
    "        Returns:\n",
    "            The MPE value (class label) of class_var given evidence\n",
    "        '''       \n",
    "        ...\n",
    "        return ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed test case !!!\n",
      "Failed test case !!!\n"
     ]
    }
   ],
   "source": [
    "##################################################################################\n",
    "## TEST CODE                                                                    ##\n",
    "## Note: More hidden tests will be used. You should create more tests yourself. ##\n",
    "##################################################################################\n",
    "\n",
    "def _test(statement):\n",
    "    if statement:\n",
    "        print(\"Passed test case\")\n",
    "    else:\n",
    "        print(\"Failed test case !!!\")\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "BN = BayesNet(G)\n",
    "\n",
    "BN.learn_outcome_space(data)\n",
    "BN.learn_parameters(data, alpha=1)\n",
    "\n",
    "evidence = {'Age': '35-49', \n",
    "    'Location': 'LolwOutQuad', \n",
    "    'MC': 'No', \n",
    "    'SkinRetract': 'No', \n",
    "    'NippleDischarge': 'No',\n",
    "    'AD': 'No',\n",
    "    'FibrTissueDev': 'No', \n",
    "    'Spiculation': 'No',\n",
    "    'Margin': 'Well-defined', \n",
    "    'Mass': 'No',\n",
    "    'Shape': 'Other', \n",
    "    'Size': '<1cm',\n",
    "    'BreastDensity': 'high',\n",
    "    'Metastasis': 'no',\n",
    "    'LymphNodes': 'no'}\n",
    "\n",
    "_test(abs(BN.predict_proba('BC', evidence)['No'] - 0.989) < 0.01)\n",
    "_test(BN.predict('BC', evidence) == 'No')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5 Marks] Task 6 - Na√Øve Bayes classifier structure\n",
    "\n",
    "Let's work now with the Na√Øve Bayes classifier. Notice that the Na√Øve Bayes is a Bayesian network with a pre-defined structure. Thus, we can create a new class for this classifier derived from the ``BayesNet`` class implemented in the tutorials.\n",
    "\n",
    "As this classifier is a Bayesian network with a pre-defined structure (graph), we will start creating a new function, ``NB.learn_structure(data, class_var)``, that learns the Na√Øve Bayes graph structure from a pandas dataframe using ``class_var`` as the class variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for NB.learn_structure(data, class_var) in this cell\n",
    "\n",
    "class NaiveBayes(BayesNet):\n",
    "    \n",
    "    def learn_structure(self, data, class_var):\n",
    "        '''\n",
    "        Arguments:\n",
    "            data:        A pandas dataframe\n",
    "            class_var:   Variable identifier to be classified\n",
    "        Returns:\n",
    "            Sets self.graph with the structure of the Na√Øve Bayes classifier for the attributes in data\n",
    "        '''\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"8pt\" height=\"8pt\"\n",
       " viewBox=\"0.00 0.00 8.00 8.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 4)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-4 4,-4 4,4 -4,4\"/>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f15430dcd10>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##################################################################################\n",
    "## TEST CODE                                                                    ##\n",
    "## Note: More hidden tests will be used. You should create more tests yourself. ##\n",
    "##################################################################################\n",
    "\n",
    "def _test(statement):\n",
    "    if statement:\n",
    "        print(\"Passed test case\")\n",
    "    else:\n",
    "        print(\"Failed test case !!!\")\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "NB = NaiveBayes()\n",
    "NB.learn_structure(data, 'BC')\n",
    "NB.graph.show()                  # You should see a star-like graph with 'BC' pointing to all other attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5 Marks] Task 7 - Na√Øve Bayes classification\n",
    "\n",
    "Similarly to Task 5, we will create two methods for implementing a classification procedure, but now the Na√Øve Bayes model. **To make things different, we will work with log probabilities this time. This is a very popular procedure for the Na√Øve Bayes classifier when used in text mining, as these applications often work with thousands of variables, such as words.**\n",
    "\n",
    "The method ``NB.predict_log_proba(class_var, evidence)`` **efficiently** computes the probability of an attribute ``class_var`` with complete data. As we are working with complete data, ``evidence`` instantiates all variables but `class_var`. This method returns a ``DiscreteFactor`` object with ``class_var`` as a single variable and the probabilities associated with each ``class_var`` value.\n",
    "\n",
    "The method ``NB.predict(class_var, evidence)`` uses the method ``predict_log_proba`` to implement the classification with complete data. This function should return the MPE value for the attribute `class_var` given the `evidence`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for NB.predict_log(class_var, evidence) and NB.predict(self, class_var, evidence) in this cell\n",
    "\n",
    "class NaiveBayes(NaiveBayes):\n",
    "    \n",
    "    def predict_log_proba(self, class_var, evidence):\n",
    "        '''\n",
    "        Arguments:\n",
    "            class_var:   Variable identifier to be classified\n",
    "            evidence:    Python dictionary with one instantiation to all variables but class_var\n",
    "        Returns:\n",
    "            A factor object with class_var as the single variable and the probabilities associated with each ``class_var`` value given evidence\n",
    "        '''        \n",
    "        ...\n",
    "        return ...\n",
    "\n",
    "    def predict(self, class_var, evidence):\n",
    "        '''\n",
    "        Arguments:\n",
    "            class_var:   Variable identifier to be classified\n",
    "            evidence:    Python dictionary with one instantiation to all variables but class_var\n",
    "        Returns:\n",
    "            The MPE value (class label) of class_var given evidence\n",
    "        '''\n",
    "        ...\n",
    "        return ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed test case !!!\n"
     ]
    }
   ],
   "source": [
    "##################################################################################\n",
    "## TEST CODE                                                                    ##\n",
    "## Note: More hidden tests will be used. You should create more tests yourself. ##\n",
    "##################################################################################\n",
    "\n",
    "def _test(statement):\n",
    "    if statement:\n",
    "        print(\"Passed test case\")\n",
    "    else:\n",
    "        print(\"Failed test case !!!\")\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "NB = NaiveBayes()\n",
    "NB.learn_outcome_space(data)\n",
    "NB.learn_structure(data, 'BC')\n",
    "NB.learn_parameters(data, alpha=1)\n",
    "evidence = {'Age': '35-49', \n",
    "    'Location': 'LolwOutQuad', \n",
    "    'MC': 'No', \n",
    "    'SkinRetract': 'No', \n",
    "    'NippleDischarge': 'No',\n",
    "    'AD': 'No',\n",
    "    'FibrTissueDev': 'No', \n",
    "    'Spiculation': 'No',\n",
    "    'Margin': 'Well-defined', \n",
    "    'Mass': 'No',\n",
    "    'Shape': 'Other', \n",
    "    'Size': '<1cm',\n",
    "    'BreastDensity': 'high',\n",
    "    'Metastasis': 'no',\n",
    "    'LymphNodes': 'no'}\n",
    "\n",
    "_test(NB.predict('BC', evidence) == 'No')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [15 Marks] Task 8 - Tree-augmented Na√Øve Bayes structure\n",
    "\n",
    "Let's work now with the Tree-augmented Na√Øve Bayes classifier. We will start creating a new function, ``TAN.learn_structure(data, class_var)``, that learns the Tree-augmented Bayes graph structure from a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for TAN.learn_structure(data, class_var) in this cell\n",
    "\n",
    "class TANet(BayesNet):\n",
    "\n",
    "    def learn_structure(data, class_var):\n",
    "        '''\n",
    "        Arguments:\n",
    "            data:        A pandas dataframe\n",
    "            class_var:   Variable identifier to be classified\n",
    "        Returns:\n",
    "            Sets self.graph with a Graph object containing the structure of the TAN classifier for the attributes in data and class_var\n",
    "        '''\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TANet.learn_structure() got multiple values for argument 'class_var'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [80], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m##################################################################################\u001b[39;00m\n\u001b[1;32m     14\u001b[0m TN \u001b[38;5;241m=\u001b[39m TANet()\n\u001b[0;32m---> 15\u001b[0m \u001b[43mTN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_var\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBC\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m _test(\u001b[38;5;28mlen\u001b[39m(TN\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mchildren(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBC\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(TN\u001b[38;5;241m.\u001b[39mgraph)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     17\u001b[0m _test(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFibrTissueDev\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m TN\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mchildren(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSpiculation\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSpiculation\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m TN\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mchildren(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFibrTissueDev\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mTypeError\u001b[0m: TANet.learn_structure() got multiple values for argument 'class_var'"
     ]
    }
   ],
   "source": [
    "##################################################################################\n",
    "## TEST CODE                                                                    ##\n",
    "## Note: More hidden tests will be used. You should create more tests yourself. ##\n",
    "##################################################################################\n",
    "\n",
    "def _test(statement):\n",
    "    if statement:\n",
    "        print(\"Passed test case\")\n",
    "    else:\n",
    "        print(\"Failed test case !!!\")\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "TN = TANet()\n",
    "TN.learn_structure(data, class_var='BC')\n",
    "_test(len(TN.graph.children('BC')) == len(TN.graph)-1)\n",
    "_test('FibrTissueDev' in TN.graph.children('Spiculation') or 'Spiculation' in TN.graph.children('FibrTissueDev'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5 Marks] Task 9 - Accuracy estimation\n",
    "\n",
    "We have finished implementing the models and will compare their classification performance. \n",
    "\n",
    "We start with the method ``assess`` which computes the accuracy of a given model. The model can be a Na√Øve Bayes, Bayes Net or a TAN. To work with different models, ``assess`` will call the method ``predict`` implemented for all three models.\n",
    "\n",
    "Design a new method, ``assess(model, data, class_var)``, that uses the test cases in ``data`` to assess ``model`` performance at classifying the variable ``class_var``. This function will return the model's accuracy according to the examples in ``data``.\n",
    "\n",
    "Remember that accuracy is the ratio of correct predictions to the total number of cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for assess(model, data, class_var) in this cell\n",
    "\n",
    "def assess(model, data, class_var):\n",
    "    '''\n",
    "    Arguments:\n",
    "        model:      A model object (Na√Øve Bayes, Bayes Net or TAN)\n",
    "        data:       A Pandas dataframe object\n",
    "        class_var:  Variable identifier to be classified\n",
    "    Returns:\n",
    "        The accuracy of the model in classifying the cases in data\n",
    "    '''\n",
    "    acc = 0\n",
    "    ...\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "## TEST CODE                                                                    ##\n",
    "## Note: More hidden tests will be used. You should create more tests yourself. ##\n",
    "##################################################################################\n",
    "\n",
    "def _test(statement):\n",
    "    if statement:\n",
    "        print(\"Passed test case\")\n",
    "    else:\n",
    "        print(\"Failed test case !!!\")\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "training, testing = train_test_split(data, test_size=0.3, random_state=42)\n",
    "\n",
    "BN = BayesNet(G)\n",
    "BN.learn_outcome_space(data)\n",
    "BN.learn_parameters(training, alpha=1)\n",
    "acc = assess(BN, testing, 'BC')\n",
    "_test(abs(acc-0.9085) < 0.001)\n",
    "\n",
    "NB = NaiveBayes()\n",
    "NB.learn_outcome_space(data)\n",
    "NB.learn_structure(training, 'BC')\n",
    "NB.learn_parameters(training, alpha=1)\n",
    "acc = assess(NB, testing, 'BC')\n",
    "_test(abs(acc-0.868) < 0.001)\n",
    "\n",
    "TN = TANet()\n",
    "TN.learn_outcome_space(data)\n",
    "TN.learn_structure(training, 'BC')\n",
    "TN.learn_parameters(training, alpha=1)\n",
    "acc = assess(TN, testing, 'BC')\n",
    "_test(abs(acc-0.9085) < 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5 Marks] Task 10 - Assessment with cross-validation\n",
    "\n",
    "Implement a function called `cross_validation(model, data, class_var, k)` that returns the average accuracy and standard deviation of the model specified in ``model`` using ``k``-fold cross-validation. \n",
    "\n",
    "A scaffold for this function is provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for cross_validation(model, data, class_var, k) in this cell\n",
    "\n",
    "def cross_validation(model, data, class_var, k=10):\n",
    "    '''\n",
    "    Arguments:\n",
    "        model:      A model object (Na√Øve Bayes, Bayes Net or TAN)\n",
    "        data:       A Pandas dataframe object\n",
    "        class_var:  Variable identifier to be classified\n",
    "        k:          number of cross-validation folds\n",
    "    Returns:\n",
    "        The mean accuracy and standard deviation of the model across the k-folds\n",
    "    '''      \n",
    "    accuracies = []\n",
    "    # Learn the model outcome space over the entire dataset\n",
    "\n",
    "    kf = KFold(n_splits=k, shuffle = True, random_state = 42)\n",
    "    for train, test in kf.split(data):\n",
    "        # Learn the model structure (graph) if this information is not provided\n",
    "        ...        \n",
    "        # Learn the model parameters\n",
    "        ...\n",
    "        # Test the model with assess\n",
    "        acc = ...           \n",
    "        accuracies.append(acc)\n",
    "    return np.mean(accuracies), np.std(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "## TEST CODE                                                                    ##\n",
    "## Note: More hidden tests will be used. You should create more tests yourself. ##\n",
    "##################################################################################\n",
    "\n",
    "def _test(statement):\n",
    "    if statement:\n",
    "        print(\"Passed test case\")\n",
    "    else:\n",
    "        print(\"Failed test case !!!\")\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "BN = BayesNet(G)\n",
    "acc, stddev = cross_validation(BN, data, 'BC')\n",
    "_test(abs(acc - 0.9125) < 0.01)\n",
    "\n",
    "TAN = TANet()\n",
    "acc, stddev = cross_validation(TN, data, 'BC')\n",
    "_test(abs(acc - 0.9131) < 0.01)\n",
    "\n",
    "NB = NaiveBayes()\n",
    "acc, stddev = cross_validation(NB, data, 'BC')\n",
    "_test(abs(acc - 0.8693) < 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [10 Marks] Task 11 - Helper Function for the Reliability Diagram and the Expected Calibration Error (ECE)\n",
    "\n",
    "Now, let's assess our classifiers differently. We will use their probabilistic nature to check the accuracy of their probability estimates. In other words, we will measure the **classifier calibration**.\n",
    "\n",
    "A well-calibrated classifier‚Äôs predicted probabilities are accurate representations of the actual probabilities of the events. For example, if a calibrated classifier predicts a probability of 0.8 for a positive class, then approximately 80% of those predictions should be positive.\n",
    "\n",
    "We will start with a helper function ``bin_pos_prob(model, data, class_var, pos_label, bins)``. This function divides the examples in ``data`` into ``bins``. Each bin corresponds to a probability range. We use uniform ranges for simplicity.\n",
    "\n",
    "The examples are split into bins according to the predicted probability of being a positive example given evidence, i.e., $P(class\\_var = pos\\_label | evidence)$. \n",
    "\n",
    "The function ``bin_pos_prob`` returns three lists:\n",
    "1. ``pos_num``: the number of positive instances in bin $i$.\n",
    "2. ``pos_ratio``: the faction of positive examples in bin $i$ relative to the number of instances in the same bin.\n",
    "3. ``mean_pos_prob``: the mean probability of positive given evidence for the examples in bin $i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for bin_pos_prob(model, data, class_var, pos_label, bins) in this cell\n",
    "\n",
    "def bin_pos_prob(model, data, class_var, pos_label, bins=10):\n",
    "    '''\n",
    "    Arguments:\n",
    "        model:      A model object (Na√Øve Bayes, Bayes Net or TAN)\n",
    "        data:       A Pandas dataframe object\n",
    "        class_var:  A binary variable identifier\n",
    "        pos_label:  The positive label of class_var\n",
    "        bins:       The number of bins\n",
    "    Returns:\n",
    "        pos_num:    The number of positive instances in bin i\n",
    "        pos_ratio:  The faction of positive examples in bin i relative to the number of instances in the same bin\n",
    "        mean_pos_prob: The mean probability of positive given evidence for the examples in bin i\n",
    "    '''\n",
    "\n",
    "    # Create the bin edges\n",
    "    bin_edges = np.linspace(0.0, 1.0, bins + 1)\n",
    "    \n",
    "    # Initialize arrays to store the fraction of positives and the mean predicted values for each bin\n",
    "    pos_num = np.zeros(bins)\n",
    "    pos_ratio = np.zeros(bins)\n",
    "    mean_pos_prob = np.zeros(bins)\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    return pos_num, pos_ratio, mean_pos_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "## TEST CODE                                                                    ##\n",
    "## Note: More hidden tests will be used. You should create more tests yourself. ##\n",
    "##################################################################################\n",
    "\n",
    "def _test(statement):\n",
    "    if statement:\n",
    "        print(\"Passed test case\")\n",
    "    else:\n",
    "        print(\"Failed test case !!!\")\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "training, testing = train_test_split(data, test_size=0.3, random_state=42)\n",
    "\n",
    "BN = BayesNet(G)\n",
    "\n",
    "BN.learn_outcome_space(data)\n",
    "BN.learn_parameters(training, alpha=1)\n",
    "pos_num, pos_ratio, mean_pos_prob = bin_pos_prob(BN, testing, 'BC', 'No', 5)\n",
    "_test(pos_num[0] == 1965)\n",
    "_test(abs(pos_ratio[0] - 0.00610687) < 0.001)\n",
    "_test(abs(mean_pos_prob[0] - 0.00790498) < 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reliability diagram \n",
    "\n",
    "This task is not marked. The cell below plots the reliability diagram using the ``bin_pos_prob`` function implemented in the previous task.\n",
    "\n",
    "A reliability diagram is a graphical representation used to assess the calibration of probabilistic classifiers. It compares a model's predicted probabilities against the actual observed frequencies of the outcomes. \n",
    "\n",
    "The x-axis represents the predicted probability (e.g., the probability of a positive class), while the y-axis represents the observed frequency of the positive class. Ideally, a perfectly calibrated model will have points on the diagonal line (y=x), indicating that the predicted probabilities match the observed frequencies. Deviations from this line indicate miscalibration, with points above the line suggesting underconfidence and points below the line suggesting overconfidence in the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reliability_plot(model, data, class_var, pos_label, bins=10):\n",
    "    '''\n",
    "    Arguments:\n",
    "        model:      A model object (Na√Øve Bayes, Bayes Net or TAN)\n",
    "        data:       A Pandas dataframe object\n",
    "        class_var:  A binary variable identifier\n",
    "        pos_label:  The positive label of class_var\n",
    "        bins:       The number of bins\n",
    "    Returns:\n",
    "        Plots the reliability diagram of the model in classifying the cases in data\n",
    "    '''        \n",
    "    \n",
    "    pos_num, pos_ratio, mean_pos_prob = bin_pos_prob(model, data, class_var, pos_label, bins)\n",
    "    \n",
    "    # Create a figure with two subplots using GridSpec\n",
    "    fig = plt.figure(figsize=(6, 8))\n",
    "    gs = GridSpec(2, 1, height_ratios=[1, .25])\n",
    "\n",
    "    ax0 = fig.add_subplot(gs[0, 0])\n",
    "    ax1 = fig.add_subplot(gs[1:, 0])\n",
    "\n",
    "    # Plot the reliability diagram\n",
    "    ax0.plot(mean_pos_prob, pos_ratio, \"s-\", label=\"Calibration Curve\")\n",
    "    ax0.plot([0, 1], [0, 1], \"k--\", label=\"Perfectly Calibrated\")\n",
    "    ax0.set_title('Reliability Diagram')\n",
    "    ax0.set_xlabel('Mean Positive Probability')\n",
    "    ax0.set_ylabel('Fraction of Actual Positives')\n",
    "    ax0.legend()\n",
    "\n",
    "    bin_edges = np.linspace(0.0, 1.0, bins + 1)\n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2    \n",
    "\n",
    "    # Plot the histogram of the number of positive cases per bin\n",
    "    ax1.bar(bin_centers, pos_num, edgecolor='black', width = 0.1)\n",
    "    ax1.set_title('Histogram of Positive Counts')\n",
    "    ax1.set_xlabel('Mean Positive Probability')\n",
    "    ax1.set_ylabel('Positive Count')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "## TEST CODE                                                                    ##\n",
    "## Note: More hidden tests will be used. You should create more tests yourself. ##\n",
    "##################################################################################\n",
    "\n",
    "def _test(statement):\n",
    "    if statement:\n",
    "        print(\"Passed test case\")\n",
    "    else:\n",
    "        print(\"Failed test case !!!\")\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "training, testing = train_test_split(data, test_size=0.3, random_state=42)\n",
    "\n",
    "BN = BayesNet(G)\n",
    "\n",
    "BN.learn_outcome_space(data)\n",
    "BN.learn_parameters(training, alpha=1)\n",
    "print(\"*** BAYES NET ***\")\n",
    "reliability_plot(BN, testing, 'BC', 'No')\n",
    "\n",
    "NB = NaiveBayes()\n",
    "NB.learn_outcome_space(data)\n",
    "NB.learn_structure(training, 'BC')\n",
    "NB.learn_parameters(training, alpha=1)\n",
    "print(\"*** NA√èVE BAYES ***\")\n",
    "reliability_plot(NB, testing, 'BC', 'No')\n",
    "\n",
    "TN = TANet()\n",
    "TN.learn_outcome_space(data)\n",
    "TN.learn_structure(training, 'BC')\n",
    "TN.learn_parameters(training, alpha=1)\n",
    "print(\"*** TANet ***\")\n",
    "reliability_plot(TN, testing, 'BC', 'No')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5 Marks] Task 12 - The Expected Calibration Error (ECE)\n",
    "\n",
    "This task computes a probabilistic classifier's Expected Calibration Error (ECE). The ECE will be useful in providing a numerical score for the calibration quality of a given model.\n",
    "\n",
    "The ECE measures the average discrepancy between predicted probabilities and the actual outcomes. ECE is computed by partitioning the predictions into bins, calculating the absolute difference between the average predicted probability and the actual fraction of positive instances in each bin, and then averaging these differences, weighted by the number of samples in each bin. A lower ECE indicates better calibration, meaning the predicted probabilities more accurately reflect the true likelihood of the outcomes.\n",
    "\n",
    "The formula for the Expected Calibration Error (ECE) is:\n",
    "\n",
    "$ \\text{ECE} = \\sum_{i=1}^{b} \\frac{|B_i|}{n} \\cdot |\\text{acc}(B_i) - \\text{conf}(B_i)| $\n",
    "\n",
    "where:\n",
    "- $b$ is the number of bins.\n",
    "- $|B_i|$ is the number of samples in bin $i$.\n",
    "- $n$ is the total number of samples.\n",
    "- $\\text{acc}(B_i)$ is the observed frequency of the positive class in bin $i$.\n",
    "- $\\text{conf}(B_i)$ is the average predicted positive probability in bin $i$.\n",
    "\n",
    "In other words, for each bin, the ECE calculates the absolute difference between the average predicted probability and the actual fraction of positives, multiplies this difference by the proportion of samples in that bin, and sums these values across all bins to get the final ECE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop your code for bin_pos_prob(model, data, class_var, pos_label, bins) in this cell\n",
    "\n",
    "def ECE(model, data, class_var, pos_label, bins=10):\n",
    "    '''\n",
    "    Arguments:\n",
    "        model:      A model object (Na√Øve Bayes, Bayes Net or TAN)\n",
    "        data:       A Pandas dataframe object\n",
    "        class_var:  A binary variable identifier\n",
    "        pos_label:  The positive label of class_var\n",
    "        bins:       The number of bins\n",
    "    Returns:\n",
    "        Returns the Expected Calibration Error (ECE)\n",
    "    '''        \n",
    "    ece = 0.0\n",
    "    ...\n",
    "    return ece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "## TEST CODE                                                                    ##\n",
    "## Note: More hidden tests will be used. You should create more tests yourself. ##\n",
    "##################################################################################\n",
    "\n",
    "def _test(statement):\n",
    "    if statement:\n",
    "        print(\"Passed test case\")\n",
    "    else:\n",
    "        print(\"Failed test case !!!\")\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "training, testing = train_test_split(data, test_size=0.3, random_state=42)\n",
    "\n",
    "BN = BayesNet(G)\n",
    "\n",
    "BN.learn_outcome_space(data)\n",
    "BN.learn_parameters(training, alpha=1)\n",
    "ece = ECE(BN, testing, 'BC', 'No')\n",
    "_test(abs(ece-0.0085) < 0.001)\n",
    "\n",
    "NB = NaiveBayes()\n",
    "NB.learn_outcome_space(data)\n",
    "NB.learn_structure(data, 'BC')\n",
    "NB.learn_parameters(training, alpha=1)\n",
    "ece = ECE(NB, testing, 'BC', 'No')\n",
    "_test(abs(ece-0.0591) < 0.001)\n",
    "\n",
    "TN = TANet()\n",
    "TN.learn_outcome_space(data)\n",
    "TN.learn_structure(data, 'BC')\n",
    "TN.learn_parameters(training, alpha=1)\n",
    "ece = ECE(TN, testing, 'BC', 'No')\n",
    "_test(abs(ece-0.0160) < 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [20 Marks] Task 13 - Report\n",
    "\n",
    "Write a report (**with less than 500 words**) summarising your findings in this assignment. Your report should address the following:\n",
    "\n",
    "a. Make a summary and discussion of the experimental results. You can analyse your results from different aspects such as accuracy, calibration runtime, coding complexity and independence assumptions.\n",
    "\n",
    "b. Discuss the time and memory complexity of the implemented algorithms.\n",
    "\n",
    "Use Markdown and Latex to write your report in the Jupyter Notebook. If you want, develop some plots using Matplotlib to illustrate your results. Be mindful of the maximum number of words. Please be concise and objective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Write your report in one or more cells here.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
